{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUOHeJhXWEFh",
        "colab_type": "text"
      },
      "source": [
        "# **CLASIFICACION**\n",
        "\n",
        "Veremos los algoritmos de clasificacion mas representativos y la forma de seleccionar los parametros optimos a traves de CV:\n",
        "\n",
        "# **1. Formulacion**\n",
        "\n",
        "Si tenemos una base de datos de entrenamiento de **$N$**\n",
        " entradas con forma de :\n",
        "\n",
        "\n",
        "*   $(\\mathbf{x}^{(i)},y^{(i)})$, donde $\\mathbf{x}\\in\\mathbb{R}^D$ es una muestra   \n",
        "*   La variable $y$ de salida, es categorica o discreta y solo puede pertenecer a  $y\\in\\{0,1\\}$ o $y\\in\\{0,1, \\ldots, M-1\\}$ en funcion de si el problema es **binario** o si tiene **M categorias**.\n",
        "\n",
        "**Objetivo**: Proponer una hipotesis  $h(\\mathbf{x},y)$ que usaremos para estimar la clase mas verosimil a la que perteneceria un nuevo punto $\\mathbf{x}^*$. Siguiendo la siguiente premisa: \n",
        "\n",
        "\\begin{align}\n",
        "\\hat{y}^* =  {\\arg \\max}_{y\\in\\{0,1,\\ldots, M-1\\}} h(\\mathbf{x}^*,y)\n",
        "\\end{align}\n",
        "\n",
        "Se pueden dar dos casos en la salida del clasificador:\n",
        "\n",
        "\n",
        "\n",
        "*   ($\\hat{y}^*=y^*$), acierto \n",
        "*   ($\\hat{y}^*\\neq y^*$), error\n",
        "\n",
        "Por tanto, el clasificador debe estar diseñado para intentar optimizar una funcion de coste que minimiza la media de clases mal clasificadas (**classification error, CE**):\n",
        "\n",
        "$$ CE = \\frac{1}{N}\\sum_{i=1}^N \\mathbb{I}[y^{(i)}\\neq \\hat{y}^{(i)}] $$\n",
        "\n",
        "$\\mathbb{I}[\\cdot]$ es la funcion indicador que devuelve uno si se da lo de dentro, si no devuelve cero.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnwAJIqTY_sx",
        "colab_type": "text"
      },
      "source": [
        "**NOTA:** A veces esto no es facil y se usan otras tecnicas de ML como minimizar el limite superior del error de clasificacion.\n",
        "\n",
        "En otro casos se usa la **Bayesian decision theory**, donde se sabe que el decisor con menor probabilidad de error viene dado por el **MAP** (maximum a posteriori):\n",
        "\\begin{align}\n",
        "\\hat{y}^* =  {\\arg \\min}_{y\\in\\{0,1,\\ldots, M-1\\}} P(Y \\neq y|\\mathbf{x}^*) = {\\arg \\max}_{y\\in\\{0,1,\\ldots, M-1\\}} P(Y = y|\\mathbf{x}^*) \n",
        "\\end{align}\n",
        "\n",
        "Siendo $P(Y=y|\\mathbf{x}^*)$ la **posterior probability** de la clase $y$. Es decir, este clasificador primero estima la probailidad a posteriori de cada clase, para despues aplicar el criterio de decision previa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wo4BDc2Taan8",
        "colab_type": "text"
      },
      "source": [
        "## **2. CLASIFICADORES**\n",
        "\n",
        "### **2.1 K-NN**\n",
        "\n",
        "Empezaremos con este clasificador **no parametrico**. Este clasificador simplemente reemplaza el valor promedio de vecinos mas cercanos por el valor de una votacion (numero mayor de clases mas cercanas).\n",
        "\n",
        "Dado un punto $\\mathbf{x}^*$ el valor predicho es obtenido a traves de:\n",
        "\\begin{align}\n",
        "\\hat{y}^* =  {\\arg \\max}_{y\\in\\{0,1,\\ldots, M-1\\}} h(\\mathbf{x}^*,y)\n",
        "\\end{align}\n",
        "\n",
        "La funcion hipotesis $h(\\mathbf{x},y)$ viene definida por:\n",
        "\n",
        "\\begin{align}\n",
        "h(\\mathbf{x}^*,y) = \\frac{1}{K}\\sum_{k\\in \\mathcal{S}_{K}(\\mathbf{x}^*)} \\mathbb{I}[y^{(k)}==y],\n",
        "\\end{align}\n",
        "\n",
        "\n",
        "\n",
        "*   $\\mathcal{S}_{K}$ numero de **$K$** puntos de entrenamiento cercanos a $\\mathbf{x}^*$ y definidos a traves de la metrica $d(\\mathbf{x}^{(i)},\\mathbf{x}^*)$**\n",
        "*   Generalmente se usa la *distancia* *Euclideana*\n",
        "\n",
        "\\begin{align}\n",
        "d(\\mathbf{x}^{(i)},\\mathbf{x}^*) = \\left|\\left|\\mathbf{x}^{(i)}-\\mathbf{x}^*\\right|\\right|^2\n",
        "\\end{align}\n",
        "\n",
        "**Nota:** La hipotesisi $h(\\mathbf{x},y)$ esta aproximando la probabilidad a posteriori de cada clase $P(Y=y|\\mathbf{x}^*)$. Promediando el numero de vecinos que pertencen a cada clase. Por tanto el classificador final es un MAP:\n",
        "\\begin{align}\n",
        "y* = {\\arg \\max}_{y\\in\\{0,1,\\ldots, M-1\\}} P(Y=y|\\mathbf{x}^*) \n",
        "\\end{align}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdjq2yphc5Bs",
        "colab_type": "text"
      },
      "source": [
        "### **Evaluacion**\n",
        "\n",
        "En los problemas de clasificacion a menudo se evalua a traves de:\n",
        "\n",
        "\n",
        "*   Classification Error\n",
        "\n",
        "$$ CE = \\frac{1}{N}\\sum_{i=1}^N \\mathbb{I}[y^{(i)}\\neq \\hat{y}^{(i)}] $$\n",
        "*   Accuracy\n",
        "$$ Acc =  1- CE = \\frac{1}{N}\\sum_{i=1}^N \\mathbb{I}[y^{(i)}= \\hat{y}^{(i)}] $$\n",
        "\n",
        "Se puede usar el metodo *score()* de [*sklearn K-NN classifier implementation*](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) o la funcion [GridSearchCV( )](http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1uYKpI1d9AW",
        "colab_type": "text"
      },
      "source": [
        "### **2.3 Regresion Logistica-Logistic Regression (LR)**\n",
        "\n",
        "#### **2.1 Modelo LR**\n",
        "\n",
        "El modelo **regresion logisitica** asume que las *posterior probabilities* vienen dadas por:\n",
        "\n",
        "$$P(Y=1| {\\bf x}) =\\displaystyle \\frac{\\exp({\\bf w}^T {\\bf x})}{1+\\exp({\\bf w}^T {\\bf x})} =  \\frac{1}{1+\\exp(-{\\bf w}^T {\\bf x})}$$\n",
        "$$ P(Y=0| {\\bf x}) = 1- P(Y=1| {\\bf x}) = \\frac{1}{1+\\exp({\\bf w}^T {\\bf x})}$$\n",
        "\n",
        "Donde el vector de pesos $\\bf w$ son los parametros del clasificador que tenemos que aprender.\n",
        "\n",
        "Mediante la definicion de estas probabilidades a posteriorir, se puede obtener un **clasificador lineal**, donde el limite de clasificacion del MAP es linel y es definido por los puntos donde $P(Y=1| {\\bf x})=P(Y=0| {\\bf x})$):\n",
        "\n",
        "$$\\log \\frac{P(Y=1| {\\bf x})}{P(Y=0| {\\bf x})} = {\\bf w}^T {\\bf x} = 0$$ \n",
        "\n",
        "#### **2.1 Model Inference**\n",
        "Para aprender los valores de los pesos $\\bf w$ (**inference learning**). el modelo LR maximiza la *likelihood* de $\\bf w$ sobre los datos de entrenamiento:\n",
        "\n",
        "$$\\bf w^* =  \\displaystyle \\underset{{\\bf w}}{\\operatorname{max}} \\prod_{i=1}^N p(y^{(i)}|\\mathbf{x}^{(i)},\\bf w) = \\displaystyle \\underset{{\\bf w}}{\\operatorname{max}}  L({\\bf w})$$\n",
        "\n",
        "La probabilididad de la likelihood de $\\bf w$ sobre los datos de ${\\bf x}$ es  $P(Y=1| {\\bf x})=\\frac{1}{1+\\exp(-{\\bf w}^T {\\bf x})}$si si etiqueta es $1$, si no, $1- P(Y=1| {\\bf x}) $ perteneceria a la clase $0$. entonces la funcion likelihood seria:\n",
        "\n",
        "$$L({\\bf w}) = \\prod_{i=1}^N P(Y=1| {\\bf x}^{(i)})^{y^{(i)}}\\left(1- P(Y=1| {\\bf x}^{(i)}) \\right)^{1-y^{(i)}} $$\n",
        "\n",
        "Para $N$ observaciones la funcion quedaria:\n",
        "$$l({\\bf w}) =\\log{L({\\bf w})} = \\sum_{i=1}^N \\left\\lbrace  y^{(i)}\\log \\left(  P(Y=1| {\\bf x}^{(i)})\\right)  + (1-y^{(i)}) \\log\\left(  1- P(Y=1| {\\bf x}^{(i)}) \\right)  \\right\\rbrace   $$\n",
        "$$l({\\bf w}) = \\sum_{i=1}^N \\left\\lbrace  y^{(i)} ({\\bf w}^T {\\bf x}^{(i)}) - \\log \\left( 1+ \\exp({\\bf w}^T {\\bf x}^{(i)})\\right) \\right\\rbrace   $$\n",
        "\n",
        "Los valores optimos de $\\bf w$ se pueden buscar solucionando el siguiente probelma de optimizacion:\n",
        "$$\\bf w^* =\\displaystyle \\underset{{\\bf w}}{\\operatorname{min}}\\sum_{i=1}^N \\left\\lbrace   \\log \\left( 1+ \\exp({\\bf w}^T {\\bf x}^{(i)})\\right) \\right\\rbrace  -y^{(i)} ({\\bf w}^T {\\bf x}^{(i)}) $$ \n",
        "\n",
        "**Analisis de la funcion de coste**\n",
        "\n",
        "$$\\bf w^* =\\displaystyle \\underset{{\\bf w}}{\\operatorname{min}}\\sum_{i=1}^N \\left\\lbrace   \\log \\left( 1+ \\exp({\\bf w}^T {\\bf x}^{(i)})\\right) \\right\\rbrace  -y^{(i)} ({\\bf w}^T {\\bf x}^{(i)}) $$ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFjQlUwoxku3",
        "colab_type": "text"
      },
      "source": [
        "#### **2.2.1 Regularized Versions**\n",
        "##### **2.2.1.1 Regularized Logistic Regression**\n",
        "\n",
        "Al igual que en los problemas de regresion, se puede añadir un termino de regularizacion sobre la anterior funcion de coste, para evitar problemas de sobremuestreo.\n",
        "\n",
        "* L2 regularization (Ridge):\n",
        "\n",
        "$$ \\bf w^* = \\displaystyle \\underset{{\\bf w}}{\\operatorname{min}} \\sum_{i=1}^N \\left\\lbrace   \\log \\left( 1+ \\exp({\\bf w}^T {\\bf x}^{(i)})\\right) \\right\\rbrace  -y^{(i)} ({\\bf w}^T {\\bf x}^{(i)}) + C \\Vert {\\bf w} \\Vert_2^2$$\n",
        "\n",
        "* L1 regularization (Lasso):\n",
        "\n",
        "$$ \\bf w^* = \\displaystyle \\underset{{\\bf w}}{\\operatorname{min}} \\sum_{i=1}^N \\left\\lbrace  \\log \\left( 1+ \\exp({\\bf w}^T {\\bf x}^{(i)})\\right) \\right\\rbrace  -y^{(i)} ({\\bf w}^T {\\bf x}^{(i)}) + C \\Vert {\\bf w} \\Vert_1$$\n",
        "\n",
        "Normalmente se usa la regularizacion $L2$, la $L1$ se suele emplear en casos de extraccion de caracteristicas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyJAYK-hypc7",
        "colab_type": "text"
      },
      "source": [
        "### **2.3 Decision Trees (Arboles de decision)**\n",
        "\n",
        "#### **2.3.1 Ejemplo**\n",
        "\n",
        "<img src=\"http://www.tsc.uc3m.es/~vanessa/Figs_notebooks/ML/Classification/TREE_1.jpg\" width=\"48%\" > <img src=\"http://www.tsc.uc3m.es/~vanessa/Figs_notebooks/ML/Classification/TREE_2.jpg\" width=\"48%\"> \n",
        "\n",
        "#### **2.3.2 Entrenar un arbol de decision**\n",
        "\n",
        "* Entradas: $ \\left\\lbrace {\\bf x}^{(i)} \\right\\rbrace_{i=1}^N \\in \\Re^D$ and $ \\left\\lbrace y^{(i)} \\right\\rbrace_{i=1}^N \\in \\{0,1, \\ldots, M-1\\} $.\n",
        "\n",
        "* para $d=1:D$ (para cada caracteristica)                                                             \n",
        "  * Para $u_{d,i} \\in$ {todos los valores de  $x_d$}            \\# Explore threshold values\n",
        "    * El nodo divide los datos: \n",
        "    \n",
        "        $X_{\\rm left}=\\left\\lbrace {\\bf x}^{(i)}, y^{(i)} \\right\\rbrace_{i \\in S_L}$, donde $S_L$ es el conjunto de datos con $x_d<u_{d,i}$\n",
        "        \n",
        "        $ X_{\\rm right}=\\left\\lbrace {\\bf x}^{(i)}, y^{(i)} \\right\\rbrace_{i \\in S_R}$, donde $S_R$ es el conjunto de datos con $x_d>u_{d,i}$\n",
        "    \n",
        "    * Evaluar la impureza de esta separacion como:\n",
        "    \n",
        "        $ G(u_{d,i}) = \\displaystyle \\frac{n_{\\rm left}}{N} g(X_{\\rm left}) + \\frac{n_{\\rm right}}{N} g(X_{\\rm right}) $\n",
        "    \n",
        "         donde $ g(X) $ es el indice Gini definido como:\n",
        "\n",
        "       $ g(X) = \\displaystyle \\sum_{m=0}^{M-1} P_m \\left( 1- P_m\\right) $\n",
        "        \n",
        "\t\t being $P_m$ the fraction of items classified in the class $J$.\n",
        "\t\t\n",
        "* seleccionar el umbral ($u_{d,i}$) y la caracteristica ($x_d$) minimizando $G(u_{d,i})$\n",
        "* Dividir el conjunto de datos acorde a $x_d$ y al umbral $u_{d,i}$\n",
        "* Aplicar estos pasos de man era recursiva para generar los siguientes nodos.\n",
        "\n",
        "\n"
      ]
    }
  ]
}